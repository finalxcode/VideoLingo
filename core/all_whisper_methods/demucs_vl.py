import os, sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
import torch
from rich.console import Console
from rich import print as rprint
from demucs.pretrained import get_model
from demucs.audio import save_audio
from torch.cuda import is_available as is_cuda_available
from typing import Optional
from demucs.api import Separator
from demucs.apply import BagOfModels
import gc

AUDIO_DIR = "output/audio"
RAW_AUDIO_FILE = os.path.join(AUDIO_DIR, "raw.mp3")
BACKGROUND_AUDIO_FILE = os.path.join(AUDIO_DIR, "background.mp3")
VOCAL_AUDIO_FILE = os.path.join(AUDIO_DIR, "vocal.mp3")

class PreloadedSeparator(Separator):
    def __init__(self, model: BagOfModels, shifts: int = 1, overlap: float = 0.25,
                 split: bool = True, segment: Optional[int] = None, jobs: int = 0):
        self._model, self._audio_channels, self._samplerate = model, model.audio_channels, model.samplerate
        device = "cuda" if is_cuda_available() else "mps" if torch.backends.mps.is_available() else "cpu"
        self.update_parameter(device=device, shifts=shifts, overlap=overlap, split=split,
                            segment=segment, jobs=jobs, progress=True, callback=None, callback_arg=None)

def demucs_main():
    """è¿™ä¸ªå‡½æ•°ä¸»è¦æŠŠäººå£°å’ŒèƒŒæ™¯éŸ³ä¹åˆ†å¼€"""
    if os.path.exists(VOCAL_AUDIO_FILE) and os.path.exists(BACKGROUND_AUDIO_FILE):
        rprint(f"[yellow]âš ï¸ {VOCAL_AUDIO_FILE} and {BACKGROUND_AUDIO_FILE} already exist, skip Demucs processing.[/yellow]")
        return
    
    console = Console()
    os.makedirs(AUDIO_DIR, exist_ok=True)
    
    console.print("ğŸ¤– Loading <htdemucs> model...")
    # åŠ è½½é¢„è®­ç»ƒçš„htdemucsæ¨¡å‹
    model = get_model('htdemucs')
    # åˆå§‹åŒ–ä¸€ä¸ªPreloadedSeparatorå®ä¾‹ï¼Œä½¿ç”¨åŠ è½½çš„æ¨¡å‹ï¼Œå¹¶è®¾ç½®shiftsä¸º1ï¼Œoverlapä¸º0.25
    separator = PreloadedSeparator(model=model, shifts=1, overlap=0.25)

    # æ‰“å°æ­£åœ¨åˆ†ç¦»éŸ³é¢‘çš„æ¶ˆæ¯
    console.print("ğŸµ Separating audio...")
    # ä½¿ç”¨separatorå¯¹è±¡å¤„ç†åŸå§‹éŸ³é¢‘æ–‡ä»¶ï¼Œå¾—åˆ°åˆ†ç¦»åçš„éŸ³é¢‘è¾“å‡º
    _, outputs = separator.separate_audio_file(RAW_AUDIO_FILE)

    # å®šä¹‰ä¿å­˜éŸ³é¢‘æ—¶ä½¿ç”¨çš„å‚æ•°å­—å…¸
    kwargs = {"samplerate": model.samplerate, "bitrate": 64, "preset": 2,
              "clip": "rescale", "as_float": False, "bits_per_sample": 16}

    # æ‰“å°æ­£åœ¨ä¿å­˜äººå£°éŸ³è½¨çš„æ¶ˆæ¯
    console.print("ğŸ¤ Saving vocals track...")
    # å°†åˆ†ç¦»å‡ºçš„äººå£°éŸ³é¢‘ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶
    save_audio(outputs['vocals'].cpu(), VOCAL_AUDIO_FILE, **kwargs)

    # æ‰“å°æ­£åœ¨ä¿å­˜èƒŒæ™¯éŸ³ä¹çš„æ¶ˆæ¯
    console.print("ğŸ¹ Saving background music...")
    # è®¡ç®—æ‰€æœ‰éäººå£°æºçš„éŸ³é¢‘æ€»å’Œä½œä¸ºèƒŒæ™¯éŸ³ä¹
    background = sum(audio for source, audio in outputs.items() if source != 'vocals')
    # å°†è®¡ç®—å¾—åˆ°çš„èƒŒæ™¯éŸ³ä¹ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶
    save_audio(background.cpu(), BACKGROUND_AUDIO_FILE, **kwargs)

    # Clean up memory
    del outputs, background, model, separator
    gc.collect()
    
    console.print("[green]âœ¨ Audio separation completed![/green]")

if __name__ == "__main__":
    demucs_main()
